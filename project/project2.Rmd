---
title: "SDS328 Project 2"
author: "Katie Jang"
date: "2020-12-03"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

#Data

```{r}
library(survival)
tdata <- transplant %>% na.omit
```

I will be using transplant data that has informations about the patients on the liver transplant waiting list. The data includes patient's sex, age, what year they entered the waiting list, futime (time from entry to final disposition), blood type(A,B,O,AB), and the event (final disposition: censored, death, ltx or withdraw). There are 815 observations total, but I will be removing all the observations with NAs, which comes down to 797 observations. 

##MANOVA

```{r}
library(rstatix)
library(dplyr)
library(tidyverse)
library(dplyr, warn.conflicts = FALSE)
options(dplyr.summarise.inform = FALSE)
library(lmtest)
library(sandwich)

group <- tdata$sex 
DVs <- tdata %>% select(age,year,futime)
#Test multivariate normality for each group (null: assumption met)
sapply(split(DVs,group), mshapiro_test)
#MANOVA
man1<-manova(cbind(age,year,futime)~sex, data=tdata)
summary(man1)
#Univariate ANOVA
summary.aov(man1) 
tdata%>%group_by(sex)%>%summarize(mean(age),mean(year),mean(futime))
```
From the multivariate normality assumptions for each group, the p-values were less than 0.05 for both male and females, meaning that the normality assumptions are not met. A one-way MANOVA was conducted to determine the effect of the sex (male or female) on two dependent variables (entrance year,age, and futime). The one-way MANOVA showed that for at least one DV (age, year, futime), the mean is different for one sex with a p-value of 0.02313. Next, I ran a one-way ANOVA, which showed that for the year they enetered the waiting list, there is a significant difference between the sexes. The mean age of females is 50.86, and for males, it is 50.24. The mean year of enterance for females is 1995.903, and for males is 1995.436.The mean futime for females is 208.23, and for males, it is 219.26. For alpha, I used 0.05/2 = 0.025 (1 MANOVA,1 ANOVA). The MANOVA and ANOVA results are still significant with the adjusted alpha value. The probability of a type-I error is 1-0.95^2 = 0.0975. 


##Randomization Test (F-statistic)
```{r}
fit3<-lm(age~event, data= tdata)
summary(fit3)
summary(aov(age~event,data=tdata))

F_obs<-2.233 
Fs<-replicate(5000,{ 
new<-tdata%>%mutate(age=sample(age)) 
SSW<- new%>%group_by(event)%>%summarize(SSW=sum((age-mean(age))^2))%>%
summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(age))%>%group_by(event)%>%mutate(groupmean=mean(age))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/3)/(SSW/793)
})

mean(Fs>F_obs) 

hist(Fs,prob = T); abline(v=F_obs, col="red", add=T)

```
Null hypothesis: The event or the final disposition of the patient does not explain variation in age. 
Alternate hypothesis: The event or the final disposition of the patient does explain variation in age. 

The observed f-statistic was 2.233. The randomization test revealed a p-value of 0.0818, which means we fail to reject the null hypothesis, so the event or the final disposition of the patient does not explain variation in age. None of the 5000 F-statistics (Fs) generated under the null hypothesis were bigger than the actual F statistic (F_obs) of 2.233. Specifically, there were 0.0818*5000=409 of the null Fs were bigger than the observed F. 



##Linear regression model

```{r}
##What predicts futime 
library(tidyverse)
tdata
tdata$sex<-factor(tdata$sex,labels = c("f","m"))
head(tdata,30)
#mean center 
tdata$futime_c <- tdata$futime - mean(tdata$futime)
tdata$age_c <- tdata$age - mean(tdata$age)
#dummy variables for sex
tdata<-tdata%>%mutate(y=ifelse(sex=="f",1,0))
#linear regression
fit<-lm(futime_c~sex*age_c, data= tdata)
summary(fit)
#Regression plot
tdata%>%ggplot(aes(age_c,futime_c,group=sex))+geom_point()+geom_smooth(method = 'lm',se=F)
#Assumption: linearity, homoskedsaticity, normality
breaks <- seq(min(tdata$age), max(tdata$age), len=8)
ggplot(tdata, aes(age_c, futime_c)) +geom_point(alpha=.3) +theme_bw()+geom_vline(xintercept=breaks,lty=2,color='gray50')
ggplot(tdata, aes(sex, futime_c)) +geom_point(alpha=.3) 
resids<-lm(futime_c~sex*age_c, data=tdata)$residuals
ggplot()+geom_histogram(aes(resids),bins=10)
bptest(fit) 
#uncorrected SEs
summary(fit)$coef
#corrected SEs
coeftest(fit, vcov=vcovHC(fit))

```

  Based on the coefficent estimates, 4.7656 is mean/predicted futime for males with average age. For every one unit decrease in age, there is a 0.7326 decrease in futime, on average. For males, there is a 101.0472 decrease in futime, on average compared to females. Controlling for sex, for every one increase in age, there is a 1.7788 increase in futime. 
  According to the graphs and the Breusch-Pagan test, the none of assumptions were not met.
  After correcting the SEs, there were no significant changes besides the small increase in the p-value of all the variables.
  The R^2 value is 0.001767, meaning that the model explains 0.18% of variability in futime, and the adjusted R^2 value is -0.002009, meaning that 0% explained by the model and the predictor improves the model by less than expected by chance.





##Linear regression model with bootstrapped standard errors

```{r}
samp_distn<-replicate(5000, {
boot_dat<-boot_dat<-tdata[sample(nrow(tdata),replace=TRUE),]
fit5<-lm(futime_c ~ sex*age_c, data=boot_dat)
coef(fit5)
})
## Estimated SEs
samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)

```

The estimated SEs is 17.99 for sexm, 1.6060 for age, and 1.869 for the interaction between sexm and age_c. Compared to the original SEs and robust SEs, the bootstrap SEs are nearly the same. Each variable decreased very slightly like sexm, which went from SE of 18.28 to 17.99. 



##Logistic regression model 

```{r}
##predicting sex from futime and age
fit6<-glm(y~futime+age,data=tdata,family=binomial(link="logit"))
coeftest(fit6)
exp(coef(fit6))
#confusion matrix
probs6 <-predict(fit6,type="response")
table(predict=as.numeric(probs6>.5),truth1=tdata$y)%>%addmargins
#specificity, accuracy, precision, sensitivity, AUC
#HERE'S THE CLASSIFICAITON DIAGNOSTICS FUNCTION
class_diag<-function(probs,truth){
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  f1=2*(sens*ppv)/(sens+ppv)

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE){
    truth<-as.numeric(truth)-1}
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,f1,auc)
}
class_diag(probs6,tdata$y)
#log-odds density plot
tdata$prob<-predict(fit6,type="response")
tdata$logit<-predict(fit6,type="link") 
tdata%>%ggplot()+geom_density(aes(logit,color=sex,fill=sex), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("predictor (logit)")
#ROC plot
library(plotROC) 
ROCplot<-ggplot(tdata)+geom_roc(aes(d=y,m=probs6), n.cuts=0)
ROCplot
calc_auc(ROCplot)
```
  Based on the exponentiated coefficient estimates, when futime and age are zero, the odds of being a female is 1.5789260. Controlling for age, every one-unit increase in futime multiplies odds of being a female by 1.0001706. Controlling for futime, every one-unit increase in age multiplies odds of being a female by 0.9941956. 
  The accuracy is 0.5495609, meaning approximately half of the proportion are correctly classified. The ppv is 0.5495609, meaning approximately half of the proportion classified females are actually females. The sensitivity i 1, meaning all proportion of females are correctly classified. The specificity is 0, meaning no proportion of males is correctly classified. The AUC is 0.493, which is bad, meaning that futime and age are not good predictors of the sex of the patients. 

##logistic regressions on rest of the variables

```{r}
##predicting sex from futime and age
fit7<-glm(y~abo+year+event,data=tdata,family=binomial(link="logit"))
coeftest(fit7)
exp(coef(fit7))
#confusion matrix
probs7 <-predict(fit7,type="response")
table(predict=as.numeric(probs7>.5),truth2=tdata$y)%>%addmargins
#specificity, accuracy, precision, sensitivity, AUC
#CLASSIFICAITON DIAGNOSTICS FUNCTION
class_diag<-function(probs,truth){
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  f1=2*(sens*ppv)/(sens+ppv)

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE){
    truth<-as.numeric(truth)-1}
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,f1,auc)
}
class_diag(probs7,tdata$y)
#log-odds density plot
tdata$prob1<-predict(fit7,type="response")
tdata$logit1<-predict(fit7,type="link") 
tdata%>%ggplot()+geom_density(aes(logit1,color=sex,fill=sex), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("predictor (logit1)")
#10-fold cv
set.seed(1234)
k=10 
data<-tdata[sample(nrow(tdata)),] 
folds<-cut(seq(1:nrow(tdata)),breaks=k,labels=F) 
diags<-NULL
for(i in 1:k){
train<-data[folds!=i,]
test<-data[folds==i,]
truth<-test$y 
fit7<-glm(y~abo+year+event,data=train,family="binomial")
probs7<-predict(fit7,newdata = test,type="response")
diags<-rbind(diags,class_diag(probs7,truth))
}
summarize_all(diags,mean) 
#LASSO
library(glmnet)
y<-as.matrix(tdata$y) 
x<-model.matrix(y~abo+year+event,data=tdata)[,-1] 
head(x)
x<-scale(x)
cv <- cv.glmnet(x,y, family="binomial") 
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.1se)
coef(lasso)
#Perform 10-fold CV
set.seed(1234)
k=10 
data<-tdata[sample(nrow(tdata)),] 
folds<-cut(seq(1:nrow(tdata)),breaks=k,labels=F) 
diags<-NULL
for(i in 1:k){
train<-data[folds!=i,]
test<-data[folds==i,]
truth<-test$y 
fit8<-glm(y~year,data=train,family="binomial")
probs8<-predict(fit8,newdata = test,type="response")
diags<-rbind(diags,class_diag(probs8,truth))
}
summarize_all(diags,mean) 
```

  From the in-sample classification diagnostics of the model, the accuracy is 0.587202, meaning approximately half of the proportion are correctly classified. The ppv is 0.5915966, meaning almost 0.6 proportion classified females are actually females. The sensitivity is 0.803653, meaning 0.8 proportion of females are correctly classified. The specificity is 0.3231198, meaning 0.32 proportion of males is correctly classified. The AUC is 0.5746524, which is bad, meaning that blood type (abo), year which patients were admitted, and event are not good predictors of the sex of the patients. 
  From the 10-fold cv out-of-sample classification diagnostics, the accuracy is 0.5584652, meaning approximately half of the proportion are correctly classified. The ppv is 0.5738859, meaning 0.57 proportion classified females are actually females. The sensitivity i 0.7890832, meaning all proportion of female are correctly classified. The specificity is 0.2843603, meaning 0.28 proportion of males is correctly classified. The AUC is 0.5510131, which is bad, meaning that blood type (abo), year which patients were admitted, and event are not good predictors of the sex of the patients. Compared to the in-sample AUC, the AUC of the out-of-sample is slightly worse by approximately 0.02.  
  From the Lasso, only the year, which the patients were admitted, was retained, and its coefficient estimate is 1.121943e-16. 
  The AUC from the 10-fold CV using only the variables lasso selected is 0.5586545. Comparing the model’s out-of-sample AUC to that of the logistic regressions above, the AUC of the logistric regression above improved very slightly from 0.5510131 to 0.5586545, but both of those AUC values are bad, meaning the all the variables are poor predictors of sex of the patients. 



